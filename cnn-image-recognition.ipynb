{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db48676",
   "metadata": {
    "papermill": {
     "duration": 0.002704,
     "end_time": "2026-02-18T18:51:53.607410",
     "exception": false,
     "start_time": "2026-02-18T18:51:53.604706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Block 1: Environment & Dependency Setup**  \n",
    "Initialization: Prepares the cloud workspace by installing the Gradio web framework and importing TensorFlow.  \n",
    "Verification: Confirms NVIDIA T4 GPU availability, ensuring the system can handle the heavy mathematical computations required for deep neural network training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad54799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:51:53.612753Z",
     "iopub.status.busy": "2026-02-18T18:51:53.612432Z",
     "iopub.status.idle": "2026-02-18T18:52:27.308154Z",
     "shell.execute_reply": "2026-02-18T18:52:27.307076Z"
    },
    "papermill": {
     "duration": 33.700273,
     "end_time": "2026-02-18T18:52:27.310058",
     "exception": false,
     "start_time": "2026-02-18T18:51:53.609785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.3/553.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tokenizers 0.21.0 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.4.1 which is incompatible.\r\n",
      "transformers 4.47.0 requires huggingface-hub<1.0,>=0.24.0, but you have huggingface-hub 1.4.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNum GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio -q\n",
    "\n",
    "import tensorflow as tf\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Verify GPU is active\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#SUPRESSING ERRORS: -qqq makes it extremely quiet; 2>/dev/null hides the red error/conflict text\n",
    "!pip install gradio -qqq 2>/dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ea7bb",
   "metadata": {
    "papermill": {
     "duration": 0.002802,
     "end_time": "2026-02-18T18:52:27.316315",
     "exception": false,
     "start_time": "2026-02-18T18:52:27.313513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Block 2: Data Engineering & Pipeline**  \n",
    "This block links the Agricultural Pests Dataset and uses `image_dataset_from_directory` to automatically label the 12 pest classes.  \n",
    "It splits the 6,000 images into training and validation sets while resizing them to 224 × 224 for model compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98753664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:52:27.324901Z",
     "iopub.status.busy": "2026-02-18T18:52:27.323251Z",
     "iopub.status.idle": "2026-02-18T18:52:34.682778Z",
     "shell.execute_reply": "2026-02-18T18:52:34.681977Z"
    },
    "papermill": {
     "duration": 7.36494,
     "end_time": "2026-02-18T18:52:34.684343",
     "exception": false,
     "start_time": "2026-02-18T18:52:27.319403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5494 files belonging to 12 classes.\n",
      "Using 4396 files for training.\n",
      "Found 5494 files belonging to 12 classes.\n",
      "Using 1098 files for validation.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/kaggle/input/agricultural-pests-image-dataset\"\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=64  # GPU T4 handles larger batches well\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627b424",
   "metadata": {
    "papermill": {
     "duration": 0.003181,
     "end_time": "2026-02-18T18:52:34.691251",
     "exception": false,
     "start_time": "2026-02-18T18:52:34.688070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Block 3: CNN Training & Transfer Learning**  \n",
    "This block builds a Sequential model using a pre-trained MobileNetV2 base for high-speed feature extraction.  \n",
    "It compiles the model with the Adam optimizer and trains for 10 epochs, enabling the AI to learn pest patterns with high accuracy on GPU hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106e8c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:52:34.699116Z",
     "iopub.status.busy": "2026-02-18T18:52:34.698844Z",
     "iopub.status.idle": "2026-02-18T18:53:49.300264Z",
     "shell.execute_reply": "2026-02-18T18:53:49.299441Z"
    },
    "papermill": {
     "duration": 74.607082,
     "end_time": "2026-02-18T18:53:49.301650",
     "exception": false,
     "start_time": "2026-02-18T18:52:34.694568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 292ms/step - accuracy: 0.4855 - loss: 1.7146 - val_accuracy: 0.8160 - val_loss: 0.6382\n",
      "Epoch 2/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.8427 - loss: 0.5278 - val_accuracy: 0.8415 - val_loss: 0.5209\n",
      "Epoch 3/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8713 - loss: 0.4152 - val_accuracy: 0.8443 - val_loss: 0.4877\n",
      "Epoch 4/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.8953 - loss: 0.3494 - val_accuracy: 0.8616 - val_loss: 0.4593\n",
      "Epoch 5/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9158 - loss: 0.2945 - val_accuracy: 0.8597 - val_loss: 0.4562\n",
      "Epoch 6/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9208 - loss: 0.2708 - val_accuracy: 0.8579 - val_loss: 0.4480\n",
      "Epoch 7/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9377 - loss: 0.2358 - val_accuracy: 0.8552 - val_loss: 0.4489\n",
      "Epoch 8/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9455 - loss: 0.2114 - val_accuracy: 0.8497 - val_loss: 0.4616\n",
      "Epoch 9/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9550 - loss: 0.1956 - val_accuracy: 0.8525 - val_loss: 0.4500\n",
      "Epoch 10/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9617 - loss: 0.1779 - val_accuracy: 0.8552 - val_loss: 0.4490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c3f504ca0b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MobileNetV2 is optimized for speed on GPUs\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3), \n",
    "    include_top=False, \n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False \n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(224, 224, 3)),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train for 10 epochs (T4 GPU makes this very fast)\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5cefd4",
   "metadata": {
    "papermill": {
     "duration": 0.03037,
     "end_time": "2026-02-18T18:53:49.362800",
     "exception": false,
     "start_time": "2026-02-18T18:53:49.332430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Block 4: Web Deployment & User Interface**  \n",
    "This block defines the `predict_pest` function to process user uploads and returns the top 3 classified names.  \n",
    "It launches a Gradio interface with a custom title, subtitle, and article, generating a public URL for real-time agricultural pest recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5811b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:53:49.424853Z",
     "iopub.status.busy": "2026-02-18T18:53:49.424500Z",
     "iopub.status.idle": "2026-02-18T18:53:51.096696Z",
     "shell.execute_reply": "2026-02-18T18:53:51.095734Z"
    },
    "papermill": {
     "duration": 1.705119,
     "end_time": "2026-02-18T18:53:51.098147",
     "exception": false,
     "start_time": "2026-02-18T18:53:49.393028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://2f3af1ca0ad2b1b4b2.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2f3af1ca0ad2b1b4b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_pest(img):\n",
    "    img = np.array(img.resize((224, 224)))\n",
    "    img = img[np.newaxis, ...] # Add batch dimension\n",
    "    # No rescaling needed here as it's built into the model above\n",
    "    preds = model.predict(img)\n",
    "    return {class_names[i]: float(preds[0][i]) for i in range(len(class_names))}\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict_pest,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=3),\n",
    "    \n",
    "    # Main large title\n",
    "    title=\"Agricultural Pest Classifier\",\n",
    "    \n",
    "    # Subtitle (appears smaller right below the title)\n",
    "    description=\"\"\"### ANN Agricultural Pests Classifier System.\n",
    "    \\n*Upload a clear photo to identify the species and see the confidence score.*\"\"\",\n",
    "    \n",
    "    # Optional: Add a small note at the very bottom of the app\n",
    "   article=\"\"\"\n",
    "    We developed this model using approximately 6000 realistic agricultural pests data with 12 different types of pests.<br>\n",
    "    We preferred this data over wine & spirits data coz we were driven to solving some real problems in agricultural sector.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2391573,
     "sourceId": 4036782,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3032186,
     "sourceId": 5212747,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 122.948994,
   "end_time": "2026-02-18T18:53:53.651227",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-18T18:51:50.702233",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
