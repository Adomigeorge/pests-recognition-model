{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4036782,"sourceType":"datasetVersion","datasetId":2391573},{"sourceId":5212747,"sourceType":"datasetVersion","datasetId":3032186}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Block 1: Environment & Dependency Setup**  \nInitialization: Prepares the cloud workspace by installing the Gradio web framework and importing TensorFlow.  \nVerification: Confirms NVIDIA T4 GPU availability, ensuring the system can handle the heavy mathematical computations required for deep neural network training.\n","metadata":{}},{"cell_type":"code","source":"!pip install gradio -q\n\nimport tensorflow as tf\nimport gradio as gr\nimport numpy as np\nfrom tensorflow.keras import layers, models\n\n# Verify GPU is active\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n#SUPRESSING ERRORS: -qqq makes it extremely quiet; 2>/dev/null hides the red error/conflict text\n!pip install gradio -qqq 2>/dev/null\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:50:32.393824Z","iopub.execute_input":"2026-02-18T14:50:32.394036Z","iopub.status.idle":"2026-02-18T14:51:00.926672Z","shell.execute_reply.started":"2026-02-18T14:50:32.394016Z","shell.execute_reply":"2026-02-18T14:51:00.925706Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.3/553.3 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntokenizers 0.21.0 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.4.1 which is incompatible.\ntransformers 4.47.0 requires huggingface-hub<1.0,>=0.24.0, but you have huggingface-hub 1.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNum GPUs Available:  2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Block 2: Data Engineering & Pipeline**  \nThis block links the Agricultural Pests Dataset and uses `image_dataset_from_directory` to automatically label the 12 pest classes.  \nIt splits the 6,000 images into training and validation sets while resizing them to 224 × 224 for model compatibility.\n","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/agricultural-pests-image-dataset\"\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=64  # GPU T4 handles larger batches well\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=64\n)\n\nclass_names = train_ds.class_names\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:51:20.474533Z","iopub.execute_input":"2026-02-18T14:51:20.474944Z","iopub.status.idle":"2026-02-18T14:51:28.313646Z","shell.execute_reply.started":"2026-02-18T14:51:20.474894Z","shell.execute_reply":"2026-02-18T14:51:28.312939Z"}},"outputs":[{"name":"stdout","text":"Found 5494 files belonging to 12 classes.\nUsing 4396 files for training.\nFound 5494 files belonging to 12 classes.\nUsing 1098 files for validation.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Block 3: CNN Training & Transfer Learning**  \nThis block builds a Sequential model using a pre-trained MobileNetV2 base for high-speed feature extraction.  \nIt compiles the model with the Adam optimizer and trains for 10 epochs, enabling the AI to learn pest patterns with high accuracy on GPU hardware.","metadata":{}},{"cell_type":"code","source":"# MobileNetV2 is optimized for speed on GPUs\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3), \n    include_top=False, \n    weights='imagenet'\n)\nbase_model.trainable = False \n\nmodel = models.Sequential([\n    layers.Rescaling(1./255, input_shape=(224, 224, 3)),\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(len(class_names), activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train for 10 epochs (T4 GPU makes this very fast)\nmodel.fit(train_ds, validation_data=val_ds, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:52:58.240036Z","iopub.execute_input":"2026-02-18T14:52:58.240396Z","iopub.status.idle":"2026-02-18T14:54:11.856037Z","shell.execute_reply.started":"2026-02-18T14:52:58.240374Z","shell.execute_reply":"2026-02-18T14:54:11.855273Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 312ms/step - accuracy: 0.4557 - loss: 1.7335 - val_accuracy: 0.8078 - val_loss: 0.6285\nEpoch 2/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.8366 - loss: 0.5323 - val_accuracy: 0.8424 - val_loss: 0.5203\nEpoch 3/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.8687 - loss: 0.4178 - val_accuracy: 0.8352 - val_loss: 0.4945\nEpoch 4/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.8921 - loss: 0.3522 - val_accuracy: 0.8525 - val_loss: 0.4639\nEpoch 5/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9129 - loss: 0.2984 - val_accuracy: 0.8506 - val_loss: 0.4595\nEpoch 6/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9231 - loss: 0.2717 - val_accuracy: 0.8525 - val_loss: 0.4524\nEpoch 7/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9351 - loss: 0.2392 - val_accuracy: 0.8515 - val_loss: 0.4523\nEpoch 8/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9467 - loss: 0.2121 - val_accuracy: 0.8434 - val_loss: 0.4679\nEpoch 9/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9512 - loss: 0.1958 - val_accuracy: 0.8461 - val_loss: 0.4555\nEpoch 10/10\n\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9610 - loss: 0.1775 - val_accuracy: 0.8561 - val_loss: 0.4571\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7dfea6f35ff0>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"**Block 4: Web Deployment & User Interface**  \nThis block defines the `predict_pest` function to process user uploads and returns the top 3 classified names.  \nIt launches a Gradio interface with a custom title, subtitle, and article, generating a public URL for real-time agricultural pest recognition.","metadata":{}},{"cell_type":"code","source":"def predict_pest(img):\n    img = np.array(img.resize((224, 224)))\n    img = img[np.newaxis, ...] # Add batch dimension\n    # No rescaling needed here as it's built into the model above\n    preds = model.predict(img)\n    return {class_names[i]: float(preds[0][i]) for i in range(len(class_names))}\n\ndemo = gr.Interface(\n    fn=predict_pest,\n    inputs=gr.Image(type=\"pil\"),\n    outputs=gr.Label(num_top_classes=3),\n    \n    # Main large title\n    title=\"Agricultural Pest Classifier\",\n    \n    # Subtitle (appears smaller right below the title)\n    description=\"\"\"### ANN Agricultural Pests Classifier System.\n    \\n*Upload a clear photo to identify the species and see the confidence score.*\"\"\",\n    \n    # Optional: Add a small note at the very bottom of the app\n   article=\"\"\"\n    We developed this model using approximately 6000 realistic agricultural pests data with 12 different types of pests.<br>\n    We preferred this data over wine & spirits data coz we were driven to solving some real problems in agricultural sector.\n    \"\"\"\n)\n\n\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:55:17.883338Z","iopub.execute_input":"2026-02-18T14:55:17.883718Z","iopub.status.idle":"2026-02-18T14:55:19.600249Z","shell.execute_reply.started":"2026-02-18T14:55:17.883690Z","shell.execute_reply":"2026-02-18T14:55:19.599504Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://a40b574168564c2e57.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://a40b574168564c2e57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","output_type":"stream"}],"execution_count":4}]}